{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b2ed28",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 웹 스크래핑 기초 - 연습문제\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 1부. 객관식\n",
    "\n",
    "### 1번\n",
    "웹 스크래핑(Web Scraping)의 정의로 가장 적절한 것은?\n",
    "\n",
    "1) 웹사이트를 만드는 기술\n",
    "2) 웹사이트에서 데이터를 자동으로 수집하는 기술\n",
    "3) 웹사이트의 보안을 강화하는 기술\n",
    "4) 웹사이트의 속도를 향상시키는 기술\n",
    "\n",
    "### 2번\n",
    "파이썬에서 웹 페이지를 가져오기 위해 사용하는 라이브러리는?\n",
    "\n",
    "1) urllib\n",
    "2) requests\n",
    "3) http\n",
    "4) web\n",
    "\n",
    "### 3번\n",
    "HTTP 응답 상태 코드 중 \"성공\"을 의미하는 코드는?\n",
    "\n",
    "1) 404\n",
    "2) 500\n",
    "3) 200\n",
    "4) 403\n",
    "\n",
    "### 4번\n",
    "BeautifulSoup 라이브러리의 주요 목적은?\n",
    "\n",
    "1) 웹 페이지 디자인\n",
    "2) HTML 파싱 및 데이터 추출\n",
    "3) 데이터베이스 관리\n",
    "4) 파일 압축\n",
    "\n",
    "### 5번\n",
    "다음 코드의 실행 결과는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get('https://httpbin.org/status/200')\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7da0e3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "1) 404\n",
    "2) 500\n",
    "3) 200\n",
    "4) 오류 발생\n",
    "\n",
    "### 6번\n",
    "HTML에서 제목 태그를 나타내는 것은?\n",
    "\n",
    "1) `<title>`\n",
    "2) `<header>`\n",
    "3) `<head>`\n",
    "4) `<topic>`\n",
    "\n",
    "### 7번\n",
    "BeautifulSoup에서 첫 번째 `<p>` 태그를 찾는 메서드는?\n",
    "\n",
    "1) `soup.find_first('p')`\n",
    "2) `soup.find('p')`\n",
    "3) `soup.get('p')`\n",
    "4) `soup.select('p')`\n",
    "\n",
    "### 8번\n",
    "웹 스크래핑 시 서버에 부담을 주지 않기 위해 사용하는 방법은?\n",
    "\n",
    "1) 더 빠르게 요청 보내기\n",
    "2) 요청 사이에 시간 간격 두기\n",
    "3) 한 번에 많은 데이터 요청하기\n",
    "4) User-Agent 헤더 제거하기\n",
    "\n",
    "### 9번\n",
    "다음 중 웹 스크래핑 윤리에 어긋나는 행위는?\n",
    "\n",
    "1) robots.txt 확인하기\n",
    "2) 적절한 시간 간격 두기\n",
    "3) 개인정보 무단 수집하기\n",
    "4) 공개된 데이터만 수집하기\n",
    "\n",
    "### 10번\n",
    "BeautifulSoup에서 모든 링크를 찾는 코드는?\n",
    "\n",
    "1) `soup.find('a')`\n",
    "2) `soup.find_all('a')`\n",
    "3) `soup.get_all('a')`\n",
    "4) `soup.select('a')`\n",
    "\n",
    "### 11번\n",
    "HTTP 상태 코드 404의 의미는?\n",
    "\n",
    "1) 서버 오류\n",
    "2) 접근 거부\n",
    "3) 페이지를 찾을 수 없음\n",
    "4) 요청 성공\n",
    "\n",
    "### 12번\n",
    "웹 스크래핑에서 User-Agent 헤더를 설정하는 이유는?\n",
    "\n",
    "1) 속도 향상을 위해\n",
    "2) 실제 브라우저처럼 보이게 하기 위해\n",
    "3) 보안 강화를 위해\n",
    "4) 데이터 압축을 위해\n",
    "\n",
    "### 13번\n",
    "다음 코드에서 soup 객체의 타입은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450eeadd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "1) str\n",
    "2) dict\n",
    "3) BeautifulSoup\n",
    "4) list\n",
    "\n",
    "### 14번\n",
    "HTML 태그의 속성값을 가져오는 메서드는?\n",
    "\n",
    "1) `tag.attr()`\n",
    "2) `tag.get()`\n",
    "3) `tag.attribute()`\n",
    "4) `tag.value()`\n",
    "\n",
    "### 15번\n",
    "웹 스크래핑을 시작하기 전에 확인해야 할 파일은?\n",
    "\n",
    "1) index.html\n",
    "2) robots.txt\n",
    "3) sitemap.xml\n",
    "4) config.txt\n",
    "\n",
    "---\n",
    "\n",
    "## ✍️ 2부. 주관식\n",
    "\n",
    "### 16번\n",
    "웹 스크래핑의 개념과 활용 분야를 설명하고, 실생활에서 웹 스크래핑이 어떻게 활용되는지 구체적인 예시 3가지를 들어 설명하세요. 각 예시에서 어떤 데이터를 수집하고 어떤 가치를 제공하는지도 포함하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 17번\n",
    "HTTP 프로토콜의 기본 개념과 요청-응답 과정을 설명하고, 웹 스크래핑에서 중요한 HTTP 상태 코드들(200, 404, 403, 500)의 의미와 각각에 대한 적절한 처리 방법을 설명하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 18번\n",
    "requests 라이브러리와 BeautifulSoup 라이브러리의 역할과 차이점을 설명하고, 두 라이브러리를 함께 사용하는 웹 스크래핑의 전체 과정을 단계별로 설명하세요. 각 단계에서 주의해야 할 점들도 포함하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 19번\n",
    "웹 스크래핑의 윤리적 고려사항과 법적 주의사항을 설명하고, 책임감 있는 웹 스크래핑을 위해 지켜야 할 원칙들을 구체적으로 제시하세요. robots.txt의 역할과 중요성도 함께 설명하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 20번\n",
    "다음 코드의 실행 과정을 단계별로 분석하고, 각 부분의 역할과 중요성을 상세히 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_news():\n",
    "    url = 'https://example.com/news'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        headlines = soup.find_all('h2', class_='news-title')\n",
    "        \n",
    "        for headline in headlines:\n",
    "            print(headline.text.strip())\n",
    "        \n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58eff6f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 21번\n",
    "HTML 파싱에서 발생할 수 있는 문제들(태그 없음, 구조 변경, 인코딩 문제 등)과 이에 대한 예외 처리 방법들을 설명하세요. 안정적인 웹 스크래핑 프로그램 작성을 위한 방어적 프로그래밍 기법들도 함께 제시하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 22번\n",
    "동적 웹사이트와 정적 웹사이트의 차이점을 설명하고, 각각에서 데이터를 추출할 때 고려해야 할 사항들을 설명하세요. 동적 웹사이트에서 데이터 수집의 한계와 대안 방법들도 함께 설명하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 23번\n",
    "대용량 웹 스크래핑 프로젝트를 수행할 때 고려해야 할 성능 최적화 방법들을 설명하세요. 메모리 관리, 동시성 처리, 캐싱 전략 등 실무에서 중요한 기법들을 구체적으로 제시하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "### 24번\n",
    "웹 스크래핑 프로젝트의 기획부터 완성까지의 전체 개발 프로세스를 설명하고, 각 단계에서 고려해야 할 요소들을 실무적 관점에서 설명하세요. 유지보수와 모니터링 방안도 포함하세요.\n",
    "\n",
    "**답안 작성란:**\n",
    "```\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "_________________________________________________\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 💻 3부. 실기 코딩\n",
    "\n",
    "### 25번\n",
    "**문제**: 온라인 뉴스 헤드라인 수집기를 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 주어진 HTML에서 뉴스 제목과 링크 추출\n",
    "- 수집된 데이터를 파일로 저장\n",
    "- 중복 제거 기능 구현\n",
    "- 수집 통계 표시\n",
    "- 예외 처리 포함\n",
    "\n",
    "**기본 HTML 데이터:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_news_html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "    <div class=\"news-container\">\n",
    "        <article class=\"news-item\">\n",
    "            <h2><a href=\"/news/1\">파이썬 개발자 취업률 상승</a></h2>\n",
    "            <p class=\"summary\">파이썬 개발자 수요가 급증하고 있습니다.</p>\n",
    "        </article>\n",
    "        <article class=\"news-item\">\n",
    "            <h2><a href=\"/news/2\">AI 기술의 발전</a></h2>\n",
    "            <p class=\"summary\">인공지능 기술이 빠르게 발전하고 있습니다.</p>\n",
    "        </article>\n",
    "        <article class=\"news-item\">\n",
    "            <h2><a href=\"/news/3\">웹 개발 트렌드 2024</a></h2>\n",
    "            <p class=\"summary\">올해 주목할 웹 개발 기술들을 소개합니다.</p>\n",
    "        </article>\n",
    "        <article class=\"news-item\">\n",
    "            <h2><a href=\"/news/1\">파이썬 개발자 취업률 상승</a></h2>\n",
    "            <p class=\"summary\">파이썬 개발자 수요가 급증하고 있습니다.</p>\n",
    "        </article>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084996c8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db868f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654f517",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**예상 출력:**\n",
    "```\n",
    "=== 뉴스 헤드라인 수집기 ===\n",
    "\n",
    "수집된 뉴스:\n",
    "1. 파이썬 개발자 취업률 상승 (/news/1)\n",
    "2. AI 기술의 발전 (/news/2)  \n",
    "3. 웹 개발 트렌드 2024 (/news/3)\n",
    "\n",
    "수집 통계:\n",
    "- 총 발견된 기사: 4개\n",
    "- 중복 제거 후: 3개\n",
    "- 저장 완료: news_headlines.txt\n",
    "\n",
    "프로그램 실행 완료!\n",
    "```\n",
    "\n",
    "### 26번\n",
    "**문제**: 온라인 쇼핑몰 상품 가격 비교 시스템을 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 여러 쇼핑몰의 상품 정보 수집\n",
    "- 가격 비교 및 최저가 찾기\n",
    "- 상품 정보를 CSV 파일로 저장\n",
    "- 가격 변동 추적 기능\n",
    "- 예외 처리 및 로그 기능\n",
    "\n",
    "**샘플 쇼핑몰 HTML:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a055717",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_sites = {\n",
    "    'site_a': \"\"\"\n",
    "    <div class=\"product-list\">\n",
    "        <div class=\"product\">\n",
    "            <h3 class=\"product-name\">무선이어폰</h3>\n",
    "            <span class=\"price\">89,000</span>\n",
    "            <span class=\"rating\">4.5</span>\n",
    "        </div>\n",
    "        <div class=\"product\">\n",
    "            <h3 class=\"product-name\">블루투스 스피커</h3>\n",
    "            <span class=\"price\">125,000</span>\n",
    "            <span class=\"rating\">4.2</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    \n",
    "    'site_b': \"\"\"\n",
    "    <div class=\"item-container\">\n",
    "        <article class=\"item\">\n",
    "            <h2 class=\"title\">무선이어폰</h2>\n",
    "            <div class=\"cost\">79,000원</div>\n",
    "            <div class=\"score\">4.7</div>\n",
    "        </article>\n",
    "        <article class=\"item\">\n",
    "            <h2 class=\"title\">블루투스 스피커</h2>\n",
    "            <div class=\"cost\">135,000원</div>\n",
    "            <div class=\"score\">4.1</div>\n",
    "        </article>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0286f2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244cf232",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 27번\n",
    "**문제**: 부동산 매물 정보 수집 및 분석 시스템을 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 지역별 매물 정보 수집\n",
    "- 가격대별 매물 분포 분석\n",
    "- 평균 가격 및 통계 계산\n",
    "- 조건별 필터링 기능\n",
    "- 분석 결과 시각화를 위한 데이터 준비\n",
    "\n",
    "**부동산 사이트 HTML:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99eeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_html = \"\"\"\n",
    "<div class=\"property-listings\">\n",
    "    <div class=\"property\">\n",
    "        <h3 class=\"address\">서울 강남구 아파트</h3>\n",
    "        <span class=\"type\">매매</span>\n",
    "        <span class=\"price\">8억5천만원</span>\n",
    "        <span class=\"area\">84㎡</span>\n",
    "        <span class=\"floor\">15층</span>\n",
    "    </div>\n",
    "    <div class=\"property\">\n",
    "        <h3 class=\"address\">서울 서초구 빌라</h3>\n",
    "        <span class=\"type\">전세</span>\n",
    "        <span class=\"price\">5억원</span>\n",
    "        <span class=\"area\">60㎡</span>\n",
    "        <span class=\"floor\">3층</span>\n",
    "    </div>\n",
    "    <div class=\"property\">\n",
    "        <h3 class=\"address\">서울 송파구 아파트</h3>\n",
    "        <span class=\"type\">매매</span>\n",
    "        <span class=\"price\">7억2천만원</span>\n",
    "        <span class=\"area\">74㎡</span>\n",
    "        <span class=\"floor\">8층</span>\n",
    "    </div>\n",
    "    <div class=\"property\">\n",
    "        <h3 class=\"address\">부산 해운대구 아파트</h3>\n",
    "        <span class=\"type\">매매</span>\n",
    "        <span class=\"price\">4억5천만원</span>\n",
    "        <span class=\"area\">84㎡</span>\n",
    "        <span class=\"floor\">12층</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1baa2c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fa3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c058c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 28번\n",
    "**문제**: 취업 정보 수집 및 분석 플랫폼을 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 여러 채용사이트에서 공고 정보 수집\n",
    "- 직무별, 지역별, 경력별 분류\n",
    "- 급여 정보 분석 및 통계\n",
    "- 인기 기술 스택 추출\n",
    "- 취업 트렌드 분석 리포트 생성\n",
    "\n",
    "**채용 사이트 HTML:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc45bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sites_html = {\n",
    "    'tech_jobs': \"\"\"\n",
    "    <div class=\"job-listings\">\n",
    "        <div class=\"job-post\">\n",
    "            <h2 class=\"job-title\">파이썬 백엔드 개발자</h2>\n",
    "            <span class=\"company\">테크스타트업</span>\n",
    "            <span class=\"location\">서울 강남구</span>\n",
    "            <span class=\"salary\">3000-4500만원</span>\n",
    "            <span class=\"experience\">2-4년</span>\n",
    "            <div class=\"skills\">Python, Django, MySQL</div>\n",
    "        </div>\n",
    "        <div class=\"job-post\">\n",
    "            <h2 class=\"job-title\">프론트엔드 개발자</h2>\n",
    "            <span class=\"company\">웹에이전시</span>\n",
    "            <span class=\"location\">서울 마포구</span>\n",
    "            <span class=\"salary\">2500-3500만원</span>\n",
    "            <span class=\"experience\">1-3년</span>\n",
    "            <div class=\"skills\">React, JavaScript, CSS</div>\n",
    "        </div>\n",
    "        <div class=\"job-post\">\n",
    "            <h2 class=\"job-title\">데이터 분석가</h2>\n",
    "            <span class=\"company\">빅데이터회사</span>\n",
    "            <span class=\"location\">서울 서초구</span>\n",
    "            <span class=\"salary\">3500-5000만원</span>\n",
    "            <span class=\"experience\">3-5년</span>\n",
    "            <div class=\"skills\">Python, SQL, Tableau</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    \n",
    "    'general_jobs': \"\"\"\n",
    "    <section class=\"opportunities\">\n",
    "        <article class=\"opportunity\">\n",
    "            <h3>마케팅 매니저</h3>\n",
    "            <p class=\"corp\">광고대행사</p>\n",
    "            <p class=\"area\">서울 용산구</p>\n",
    "            <p class=\"pay\">2800-3800만원</p>\n",
    "            <p class=\"career\">3-5년</p>\n",
    "            <p class=\"requirements\">디지털 마케팅, 구글 애즈</p>\n",
    "        </article>\n",
    "        <article class=\"opportunity\">\n",
    "            <h3>UI/UX 디자이너</h3>\n",
    "            <p class=\"corp\">게임회사</p>\n",
    "            <p class=\"area\">성남 분당구</p>\n",
    "            <p class=\"pay\">3200-4200만원</p>\n",
    "            <p class=\"career\">2-4년</p>\n",
    "            <p class=\"requirements\">Figma, Sketch, 포트폴리오</p>\n",
    "        </article>\n",
    "    </section>\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eb9d3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48728e0f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 29번\n",
    "**문제**: 소셜미디어 트렌드 분석 시스템을 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 게시물 제목과 내용에서 키워드 추출\n",
    "- 해시태그 빈도 분석\n",
    "- 인기 토픽 트렌드 추적\n",
    "- 감정 분석 (긍정/부정/중립)\n",
    "- 시간대별 활동 패턴 분석\n",
    "\n",
    "**소셜미디어 HTML:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_html = \"\"\"\n",
    "<div class=\"feed-container\">\n",
    "    <div class=\"post\">\n",
    "        <div class=\"author\">@tech_lover</div>\n",
    "        <div class=\"content\">파이썬으로 웹 스크래핑 배우는 중! 정말 재밌어요 😊 #파이썬 #웹스크래핑 #프로그래밍</div>\n",
    "        <div class=\"timestamp\">2024-03-15 14:30</div>\n",
    "        <div class=\"likes\">125</div>\n",
    "        <div class=\"shares\">23</div>\n",
    "    </div>\n",
    "    <div class=\"post\">\n",
    "        <div class=\"author\">@data_scientist</div>\n",
    "        <div class=\"content\">BeautifulSoup 진짜 강력하다... 데이터 수집이 이렇게 쉬워도 되나? #데이터수집 #beautifulsoup #개발</div>\n",
    "        <div class=\"timestamp\">2024-03-15 16:45</div>\n",
    "        <div class=\"likes\">89</div>\n",
    "        <div class=\"shares\">12</div>\n",
    "    </div>\n",
    "    <div class=\"post\">\n",
    "        <div class=\"author\">@web_dev</div>\n",
    "        <div class=\"content\">requests 라이브러리 없이는 못 살겠어ㅠㅠ HTTP 요청이 이렇게 간단할 줄이야 #requests #python #웹개발</div>\n",
    "        <div class=\"timestamp\">2024-03-15 18:20</div>\n",
    "        <div class=\"likes\">156</div>\n",
    "        <div class=\"shares\">34</div>\n",
    "    </div>\n",
    "    <div class=\"post\">\n",
    "        <div class=\"author\">@beginner_coder</div>\n",
    "        <div class=\"content\">웹 스크래핑 너무 어려워... robots.txt도 확인해야 하고 윤리도 생각해야 하고... 힘들다 😢 #초보자 #어려움</div>\n",
    "        <div class=\"timestamp\">2024-03-15 20:15</div>\n",
    "        <div class=\"likes\">67</div>\n",
    "        <div class=\"shares\">8</div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108a80d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345bf9f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 30번\n",
    "**문제**: 종합 웹 데이터 수집 및 분석 플랫폼을 구현하세요.\n",
    "\n",
    "**요구사항:**\n",
    "- 다중 사이트 동시 스크래핑\n",
    "- 데이터 품질 검증 및 정제\n",
    "- 실시간 모니터링 및 알림\n",
    "- 수집 데이터 시각화 준비\n",
    "- 자동화된 스케줄링 시뮬레이션\n",
    "- 성능 최적화 및 에러 복구\n",
    "\n",
    "**종합 데이터 소스:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = {\n",
    "    'news_site': {\n",
    "        'url': 'https://example-news.com',\n",
    "        'html': \"\"\"\n",
    "        <div class=\"news-feed\">\n",
    "            <article class=\"news-item\" data-category=\"tech\">\n",
    "                <h2>AI 기술 발전 소식</h2>\n",
    "                <span class=\"date\">2024-03-15</span>\n",
    "                <p class=\"summary\">인공지능 기술이 새로운 전환점을 맞았습니다.</p>\n",
    "                <div class=\"metrics\">조회수: 1250, 댓글: 45</div>\n",
    "            </article>\n",
    "            <article class=\"news-item\" data-category=\"economy\">\n",
    "                <h2>경제 성장률 전망</h2>\n",
    "                <span class=\"date\">2024-03-15</span>\n",
    "                <p class=\"summary\">올해 경제 성장률이 예상치를 상회할 것으로 보입니다.</p>\n",
    "                <div class=\"metrics\">조회수: 890, 댓글: 23</div>\n",
    "            </article>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    'weather_site': {\n",
    "        'url': 'https://example-weather.com',\n",
    "        'html': \"\"\"\n",
    "        <div class=\"weather-data\">\n",
    "            <div class=\"city-weather\" data-city=\"seoul\">\n",
    "                <h3>서울</h3>\n",
    "                <span class=\"temp\">15°C</span>\n",
    "                <span class=\"humidity\">65%</span>\n",
    "                <span class=\"condition\">맑음</span>\n",
    "                <span class=\"timestamp\">2024-03-15 14:00</span>\n",
    "            </div>\n",
    "            <div class=\"city-weather\" data-city=\"busan\">\n",
    "                <h3>부산</h3>\n",
    "                <span class=\"temp\">18°C</span>\n",
    "                <span class=\"humidity\">72%</span>\n",
    "                <span class=\"condition\">흐림</span>\n",
    "                <span class=\"timestamp\">2024-03-15 14:00</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    },\n",
    "    \n",
    "    'stock_site': {\n",
    "        'url': 'https://example-stock.com',\n",
    "        'html': \"\"\"\n",
    "        <table class=\"stock-table\">\n",
    "            <tr class=\"stock-row\">\n",
    "                <td class=\"name\">삼성전자</td>\n",
    "                <td class=\"price\">75,000</td>\n",
    "                <td class=\"change\">+1,200</td>\n",
    "                <td class=\"rate\">+1.6%</td>\n",
    "                <td class=\"volume\">15,234,567</td>\n",
    "            </tr>\n",
    "            <tr class=\"stock-row\">\n",
    "                <td class=\"name\">SK하이닉스</td>\n",
    "                <td class=\"price\">128,500</td>\n",
    "                <td class=\"change\">-2,500</td>\n",
    "                <td class=\"rate\">-1.9%</td>\n",
    "                <td class=\"volume\">8,456,789</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        \"\"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a1eac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**코드 작성란:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d33533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d9e6c",
   "metadata": {},
   "source": [
    "**예상 출력:**\n",
    "```\n",
    "=== 종합 웹 데이터 수집 플랫폼 ===\n",
    "\n",
    "[ 수집 현황 ]\n",
    "✅ 뉴스 사이트: 2건 수집 완료\n",
    "✅ 날씨 사이트: 2개 도시 데이터 수집\n",
    "✅ 주식 사이트: 2개 종목 데이터 수집\n",
    "\n",
    "[ 데이터 품질 검증 ]\n",
    "- 중복 데이터: 0건\n",
    "- 누락 필드: 0건  \n",
    "- 이상치: 0건 발견\n",
    "\n",
    "[ 분석 결과 ]\n",
    "가장 인기 뉴스: AI 기술 발전 소식 (1,250 조회)\n",
    "평균 기온: 16.5°C\n",
    "주식 평균 변동률: -0.15%\n",
    "\n",
    "[ 저장 완료 ]\n",
    "- news_data.csv (2건)\n",
    "- weather_data.csv (2건)\n",
    "- stock_data.csv (2건)\n",
    "- comprehensive_report.json (종합 리포트)\n",
    "\n",
    "다음 수집 예정: 1시간 후\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 정답 및 해설\n",
    "\n",
    "### 객관식 정답\n",
    "1. ② &nbsp;&nbsp; 2. ② &nbsp;&nbsp; 3. ③ &nbsp;&nbsp; 4. ② &nbsp;&nbsp; 5. ③\n",
    "6. ① &nbsp;&nbsp; 7. ② &nbsp;&nbsp; 8. ② &nbsp;&nbsp; 9. ③ &nbsp;&nbsp; 10. ②\n",
    "11. ③ &nbsp;&nbsp; 12. ② &nbsp;&nbsp; 13. ③ &nbsp;&nbsp; 14. ② &nbsp;&nbsp; 15. ②\n",
    "\n",
    "### 주요 해설 포인트\n",
    "\n",
    "**웹 스크래핑 기본 개념**\n",
    "- 웹 스크래핑은 웹사이트에서 데이터를 자동으로 수집하는 기술\n",
    "- requests 라이브러리로 웹 페이지 가져오기\n",
    "- BeautifulSoup으로 HTML 파싱 및 데이터 추출\n",
    "\n",
    "**HTTP 기초**\n",
    "- HTTP 상태 코드 의미 파악 (200=성공, 404=없음, 403=거부, 500=서버오류)\n",
    "- 요청-응답 구조 이해\n",
    "- User-Agent 헤더의 중요성\n",
    "\n",
    "**HTML 파싱**\n",
    "- `find()`: 첫 번째 요소 찾기\n",
    "- `find_all()`: 모든 요소 찾기  \n",
    "- `get()`: 속성값 가져오기\n",
    "- CSS 선택자 활용\n",
    "\n",
    "**웹 스크래핑 윤리**\n",
    "- robots.txt 확인 필수\n",
    "- 서버 부담 최소화 (time.sleep 사용)\n",
    "- 개인정보 보호 준수\n",
    "- 이용약관 확인\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 학습 조언\n",
    "\n",
    "### 이 연습문제로 무엇을 확인할 수 있나요?\n",
    "\n",
    "**기초 이해도 (객관식)**\n",
    "- 웹 스크래핑 기본 개념과 도구들\n",
    "- HTTP 프로토콜과 상태 코드 이해\n",
    "- HTML 파싱 기본 문법\n",
    "\n",
    "**개념 이해 (주관식)**\n",
    "- 웹 스크래핑의 윤리적 고려사항\n",
    "- 실무에서의 활용 방법\n",
    "- 문제 해결 방법론\n",
    "\n",
    "**실무 적용 (실기코딩)**\n",
    "- 실제 웹사이트에서 데이터 수집\n",
    "- 대용량 데이터 처리\n",
    "- 종합적인 데이터 분석 시스템 구축\n",
    "\n",
    "### ⚠️ 중요한 주의사항\n",
    "\n",
    "**법적/윤리적 준수사항**\n",
    "- robots.txt 반드시 확인\n",
    "- 개인정보 수집 금지\n",
    "- 저작권 보호 콘텐츠 주의\n",
    "- 서버 부담 최소화\n",
    "\n",
    "**기술적 고려사항**\n",
    "- 예외 처리 필수\n",
    "- 적절한 지연 시간 설정\n",
    "- 데이터 검증 및 정제\n",
    "- 재시도 로직 구현\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 추가 연습 자료\n",
    "\n",
    "1. **Requests 공식 문서**: https://requests.readthedocs.io/\n",
    "   - HTTP 요청 라이브러리 완전 가이드\n",
    "\n",
    "2. **BeautifulSoup 문서**: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "   - HTML/XML 파싱 라이브러리 매뉴얼\n",
    "\n",
    "3. **웹 스크래핑 윤리 가이드**: https://blog.apify.com/web-scraping-ethics/\n",
    "   - 책임감 있는 웹 스크래핑 방법론\n",
    "\n",
    "4. **실습 사이트**\n",
    "   - httpbin.org - HTTP 요청 테스트용\n",
    "   - quotes.toscrape.com - 스크래핑 연습용\n",
    "   - scrape.world - 다양한 난이도별 연습\n",
    "\n",
    "5. **심화 학습 주제**\n",
    "   - Selenium을 이용한 동적 페이지 스크래핑\n",
    "   - 스크래핑 성능 최적화 기법\n",
    "   - 대용량 데이터 처리 및 저장\n",
    "\n",
    "**데이터는 새로운 시대의 석유입니다. 웹 스크래핑으로 그 보물을 발굴해보세요!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
